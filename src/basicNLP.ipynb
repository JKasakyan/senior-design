{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk import ngrams, word_tokenize, pos_tag, FreqDist\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from itertools import zip_longest\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = \"\"\"For A number of years now, work has been proceeding IN order to bring perfection to the crudely conceived idea of a transmission that would not only supply inverse reactive current for use in unilateral phase detractors, but would also be capable of automatically synchronizing cardinal grammeters. Such an instrument is the turbo encabulator.Now basically the only new principle involved is that instead of power being generated by the relative motion of conductors and fluxes, it is produced by the modial interaction of magneto-reluctance and capacitive diractance.The original machine had a base plate of pre-famulated amulite surmounted by a malleable logarithmic casing in such a way that the two spurving bearings were in a direct line with the panametric fan. The latter consisted simply of six hydrocoptic marzlevanes, so fitted to the ambifacient lunar waneshaft that side fumbling was effectively prevented.The main winding was of the normal lotus-o-delta type placed in panendermic semi-boloid slots of the stator, every seventh conductor being connected by a non-reversible tremie pipe to the differential girdle spring on the \"up\" end of the grammeters.The turbo-encabulator has now reached a high level of development, and itâ€™s being successfully used in the operation of novertrunnions. Moreover, whenever a forescent skor motion is required, it may also be employed in conjunction with a drawn reciprocation dingle arm, to reduce sinusoidal repleneration.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize and Tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lower = text.lower()\n",
    "tokensOriginalCase = word_tokenize(text)\n",
    "tokens = word_tokenize(lower)\n",
    "tagged = pos_tag(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "def treebankToWordnetPOS(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN #NOUN is the default type if no POS is given for lemmatize\n",
    "    \n",
    "lemma = []\n",
    "for word, pos in tagged:\n",
    "    root = wnl.lemmatize(word, treebankToWordnetPOS(pos))\n",
    "    lemma.append(root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Suffix Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "suffixTable = {}\n",
    "with open(\"suffixes.txt\") as f:\n",
    "    for line in f:\n",
    "        suffix = line.strip()\n",
    "        suffixTable[suffix] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Suffixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "suffixes = []\n",
    "for word in tokens:\n",
    "    for suffix in suffixTable:\n",
    "        if word.endswith(suffix):\n",
    "            suffixTable[suffix] = suffixTable.get(suffix, 0) + 1   \n",
    "            suffixes.append(suffix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create N-Grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "uni = []\n",
    "bi = []\n",
    "tri = []\n",
    "for gram in ngrams(tokens, 1):\n",
    "    uni.append(gram)\n",
    "for gram in ngrams(tokens, 2):\n",
    "    bi.append(gram)\n",
    "for gram in ngrams(tokens, 3):\n",
    "    tri.append(gram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gram Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "uniDist = FreqDist(uni)\n",
    "biDist = FreqDist(bi)\n",
    "triDist = FreqDist(tri)\n",
    "\n",
    "for gram, count in uniDist.items():\n",
    "    gram,count\n",
    "for gram, count in biDist.items():\n",
    "    gram,count\n",
    "for gram, count in triDist.items():\n",
    "    gram,count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS Grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pos = [tag for word, tag in tagged]\n",
    "\n",
    "uniPOS = []\n",
    "biPOS = []\n",
    "triPOS = []\n",
    "quadPOS = []\n",
    "pentPOS = []\n",
    "for gram in ngrams(pos, 1):\n",
    "    uniPOS.append(gram)\n",
    "for gram in ngrams(pos, 2):\n",
    "    biPOS.append(gram)\n",
    "for gram in ngrams(pos, 3):\n",
    "    triPOS.append(gram)\n",
    "for gram in ngrams(pos, 4):\n",
    "    quadPOS.append(gram)\n",
    "for gram in ngrams(pos, 5):\n",
    "    pentPOS.append(gram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POS Gram Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "uniPOSdist = FreqDist(uniPOS)\n",
    "biPOSdist = FreqDist(biPOS)\n",
    "triPOSdist = FreqDist(triPOS)\n",
    "quadPOSdist = FreqDist(quadPOS)\n",
    "pentPOSdist = FreqDist(pentPOS)\n",
    "\n",
    "for gram, count in uniPOSdist.items():\n",
    "    gram,count\n",
    "for gram, count in biPOSdist.items():\n",
    "    gram,count\n",
    "for gram, count in triPOSdist.items():\n",
    "    gram,count\n",
    "for gram, count in quadPOSdist.items():\n",
    "    gram,count\n",
    "for gram, count in pentPOSdist.items():\n",
    "    gram,count    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uppercase/Lowercase ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "capsFreq = sum([1 if letter.isupper() else 0 for letter in text])/sum([1 if letter.islower() else 0 for letter in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wordCase = []\n",
    "for word in tokensOriginalCase:\n",
    "    wordCase.append(1 if reduce(lambda upper, c: True if upper and c.isupper() else False, word, True) else 0)\n",
    "allcapsFreq = sum(wordCase)/len(wordCase)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
